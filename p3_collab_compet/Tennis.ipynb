{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define a longer timeout duration\n",
    "timeout_duration = 60  # in seconds\n",
    "\n",
    "# Launch the environment\n",
    "env = UnityEnvironment(file_name=\"Tennis_Linux/Tennis.x86_64\")\n",
    "\n",
    "# Wait for the environment to initialize\n",
    "time.sleep(timeout_duration)\n",
    "\n",
    "# Check if the environment is ready\n",
    "try:\n",
    "    env.reset()\n",
    "except Exception as e:\n",
    "    print(\"Unity environment failed to respond in time:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -7.38993645 -1.5\n",
      " -0.          0.          6.83172083  5.99607611 -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import Group\n",
    "\n",
    "group = Group(num_agents, state_size, action_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanhnq79re/miniconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\t Average Score: 0.00\n",
      "Episode 200\t Average Score: 0.00\n",
      "Episode 300\t Average Score: 0.00\n",
      "Episode 400\t Average Score: 0.00\n",
      "Episode 500\t Average Score: 0.00\n",
      "Episode 600\t Average Score: 0.00\n",
      "Episode 700\t Average Score: 0.01\n",
      "Episode 800\t Average Score: 0.02\n",
      "Episode 900\t Average Score: 0.01\n",
      "Episode 1000\t Average Score: 0.02\n",
      "Episode 1100\t Average Score: 0.01\n",
      "Episode 1200\t Average Score: 0.01\n",
      "Episode 1300\t Average Score: 0.06\n",
      "Episode 1400\t Average Score: 0.15\n",
      "Episode 1500\t Average Score: 0.14\n",
      "Episode 1600\t Average Score: 0.20\n",
      "Episode 1700\t Average Score: 0.28\n",
      "Episode 1739\t Average Score: 0.51\n",
      "Environment solved in 1739 episodes!\tAverage Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "def maddpg(n_episodes=2500, eps_start=1.0, eps_end=0.01, eps_decay=0.95):\n",
    "    mdddpg_scores = []                 # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        group.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "\n",
    "        while True:\n",
    "            actions = group.act(states, eps)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            group.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        \n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        episode_score = scores.max()\n",
    "        scores_window.append(episode_score)\n",
    "        mdddpg_scores.append(episode_score)\n",
    "        avg_reward = np.mean(scores_window)\n",
    "                \n",
    "        print('\\rEpisode {}\\t Average Score: {:.2f}'.format(i_episode, avg_reward), end=\"\")\n",
    "        \n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\t Average Score: {:.2f}'.format(i_episode, avg_reward))\n",
    "        \n",
    "        if avg_reward >= 0.5 and i_episode >= 100:\n",
    "            print('\\nEnvironment solved in {} episodes!\\tAverage Score: {:.2f}'.format(i_episode, avg_reward))\n",
    "            torch.save(group.checkpoint(), 'agents.pth')\n",
    "            break\n",
    "        \n",
    "    return mdddpg_scores\n",
    "\n",
    "\n",
    "scores = maddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plotting the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.savefig('scores.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 1.845000027678907\n"
     ]
    }
   ],
   "source": [
    "group = Group(num_agents, state_size, action_size, 0)\n",
    "state_dict = torch.load('agents.pth')\n",
    "for i, agent in enumerate(group.agents):\n",
    "    agent.actor_local.load_state_dict(state_dict[i]['actor'])\n",
    "    agent.critic_local.load_state_dict(state_dict[i]['critic'])\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "scores = np.zeros(num_agents)\n",
    "\n",
    "while True:\n",
    "    actions = group.act(states, 0)\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
